---
title: "task12"
author: "Greta Baumilaitė"
date: "Tuesday, April 26, 2016"
output: html_document
---
UZDUOTIS:  For this exercise, use the monthly Australian short-term overseas visitors data, May 1985–April 2005. (Data set: visitors in expsmooth package.)
(a) Use ets to ﬁnd the best model for these data and record the training set RMSE. You should ﬁnd that the best model is ETS(M,A,M).

```{r}
library(fpp)
library(expsmooth)
visitors #musu duomenys
tsdisplay(visitors, plot.type="scatter")
#matosi vyraujantis didejantis trendas,cikliskumas bei sezoniskumas
mod1=ets(visitors)
mod1 #kaip ir pasakyta salygoje,gavome,kad geriausias modelis ets(M,A,M)
accuracy(mod1) #RMSE=15.86105
```
(b) We will now check how much larger the one-step RMSE is on out-of-sample data using time series cross-validation. 

```{r}
k=48 # minimum size for training set
n=length(visitors) # Total number of observations
e=visitors*NA # Vector to record one-step forecast errors
for(i in 48:(n-1))
{ 
  train=ts(visitors[1:i],freq=12) 
  fit=ets(train, "MAM", damped=FALSE) 
  fc=forecast(fit,h=1)$mean 
  e[i]=visitors[i+1]-fc
} 
sqrt(mean(e^2,na.rm=TRUE)) #suskaiciuoja RMSE 
#ciklas duoda didesni RMSE,nei pries tai
#siuo atjevu RMSE=18.73602

```
(c) What would happen in the above loop if I had set train <- visitors[1:i]? 
```{r}
k=48 # minimum size for training set
n=length(visitors) # Total number of observations
e=visitors*NA # Vector to record one-step forecast errors
for(i in 48:(n-1))
{ 
  train=visitors[1:i] 
  fit=ets(train, "MAM", damped=FALSE) 
  fc=forecast(fit,h=1)$mean 
  e[i]=visitors[i+1]-fc
} 
sqrt(mean(e^2,na.rm=TRUE)) 
#pakeitus duota eilute,nebesuskaiciuoja kodas RMSE,nes duomenys prarnda laiko intervalus

```
(d) Plot e. What do you notice about the error variances? Why does this occur?
```{r}
plot(e)
plot(visitors) #grafikas parodo begant laikui didejanti trenda
# tad is paklaidu grafiko matosi paklaidos yra heteroskedastiskos, nes paklaidu issidestymas begant metams taip pat auga.

```
(e) How does this problem bias the comparison of the RMSE values from (1a) and (1b)? (Hint: think about the eﬀect of the missing values in e.) 
negalim palyginti 1a ir 1b RMSE,nes 1b duomenu yra maziau nei 1a.
1a RMSE=15.86105
1b RMSE=18.73602

(f) In practice, we will not know that the best model on the whole data set is ETS(M,A,M) until we observe all the data. So a more realistic analysis would be to allow ets to select a diﬀerent model each time through the loop. Calculate the RMSE using this approach. (Warning: it will take a while as there are a lot of models to ﬁt.)
```{r}
k=48 # minimum size for training set
n=length(visitors) # Total number of observations
e=visitors*NA # Vector to record one-step forecast errors
for(i in 48:(n-1))
{ 
  train=ts(visitors[1:i],freq=12) 
  fit=ets(train) 
  fc=forecast(fit,h=1)$mean 
  e[i]=visitors[i+1]-fc
} 
sqrt(mean(e^2,na.rm=TRUE))
#siuo atveju gauname RMSE=18.97897

```
(g) How does the RMSE computed in (1f) compare to that computed in (1b)? Does the re-selection of a model at each step make much diﬀerence?
1b RMSE=18.73602
1f RMSE=19.97897
manau reiksmingo skirtumo nera tarp situ skaiciu,tad parinkus tinkama modeli ciklas greiciau persisuka ir apskaiciuoja RMSE. 
